{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/72b2077605dd49b78f7f647d6821d10231f6bc52d7ed463da451a6a0bd1fc5ff)\n",
    "*Note: The above pictures are from the internet*\n",
    "\n",
    "# 1. OCR Technology Background\n",
    "## 1.1 Application scenarios for OCR technology\n",
    "\n",
    "* **<font color=red>What is OCR?</font>**\n",
    "\n",
    "OCRÔºàOptical Character RecognitionÔºâis one of the important directions of computer vision.The traditional definition of OCR is generally oriented to scanned document-like objects, but now we often refer to OCR as Scene Text Recognition (STR), which is mainly oriented to natural scenes, such as the plaques shown in the figure below, and other visible texts in various natural scenes.\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/c87c0e6f6c0a42cdbc552a4f973c1b0217c369194c1243558753896f3e66032c)\n",
    "<center>Figure1 Document Scene Text Recognition VS. Natural Scene Text Recognition</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "* **<font color=red>What are the application scenarios of OCR?</font>**\n",
    "\n",
    "OCR technology has rich application scenarios, a typical scenario is the structured text recognition for pendant categories widely used in daily life, such as license plate recognition, bank card information recognition, ID card information recognition, train ticket information recognition and so on. The common feature of these small pendants is that the format is fixed, so it is very suitable for automation using OCR technology, which can greatly reduce labor costs and improve efficiency.\n",
    "\n",
    "This pendant-oriented structured text recognition is currently the most widely used and relatively mature scenario for OCR.\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/56e0df91d0d34443aacb17c9a1c5c186608ee675092648a693503df7fe45e535)\n",
    "<center>Figure2 Application scenarios for OCR technology</center>\n",
    "\n",
    "In addition to pendant-oriented structured text recognition, general-purpose OCR technologies are also widely used and are often combined with other technologies to accomplish multimodal tasks, for example, in video scenarios, OCR technologies are often used for automatic translation of subtitles, content security monitoring, etc., or combined with visual features to accomplish tasks such as video understanding and video search.\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/ca2341a51eb242ee8e1afe121ce3ebbc87a113cef1b643ed9bba92d0c8ee4f0f)\n",
    "<center>Figure3 Universal OCR in multimodal scenarios</center>\n",
    "\n",
    "## 1.2 OCR Technical Challenges\n",
    "The technical difficulties of OCR can be divided into two aspects: the algorithm and the application.\n",
    "\n",
    "* **<font color=red>Algorithm</font>**\n",
    "\n",
    "The rich application scenario of OCR determines that it will have many technical difficulties. Here, eight common problems are given:\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/a56831fbf0c449fe9156a893002cadfe110ccfea835b4d90854a7ce4b1df2a4f)\n",
    "<center>Figure4 technical difficulties of OCR algorithm</center>\n",
    "\n",
    "These problems bring great technical challenges to both text detection and text recognition, and it can be seen that these challenges are mainly oriented to natural scenes, and the current academic research also focuses on natural scenes, and the common datasets in the field of OCR in academia are all natural scenes. There are many studies for these problems, and relatively speaking, recognition faces a greater challenge than detection.\n",
    "\n",
    "* **<font color=red>Application</font>**\n",
    "\n",
    "In practical applications, especially in a wide range of general scenarios, in addition to the technical difficulties at the algorithm level such as affine transformation, scale problems, insufficient lighting, and blurred shooting summarized in the previous section, OCR technology also faces two major landing difficulties:\n",
    "1. **Massive amounts of data require OCR to be able to process in real time.** OCR applications often interface with massive amounts of data, and we require or expect the data to be processed in real time, and the speed of the model to achieve real time is not a small challenge.\n",
    "2. **End-side applications require OCR models that are light enough and fast enough to recognize.** OCR applications are often deployed on mobile or embedded hardware, and end-side OCR applications generally have two modes: upload to server vs. direct recognition on the end-side. Considering that the upload-to-server approach has requirements for network, low real-time performance, and high pressure on the server when the request volume is too large, as well as the security of data transmission, we hope to complete OCR recognition directly on the end-side, while the storage space and computational capacity on the end-side are limited. and computing power is limited, so the size of the OCR model and the prediction speed have high requirements.\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/5bafdc3da1614c41a95ae39a2c36632f95e2893031a64929b9f49d4a4985cd2d)\n",
    "<center>Figure5 OCR Application Layer Technical Difficulties</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. OCR cutting-edge algorithms\n",
    "\n",
    "Although OCR is a relatively specific task, it involves a variety of technologies, including text detection, text recognition, end-to-end text recognition, document analysis, and so on. Academic research on various OCR-related technologies is proliferating, and the following section briefly describes the work related to several key technologies in the OCR task.\n",
    "\n",
    "## 2.1 Text Detection\n",
    "\n",
    "The task of text detection is to locate text regions in the input image. In recent years, there has been a wealth of academic research on text detection. One class of approaches considers text detection as a specific scenario in target detection and improves the adaptation based on generic target detection algorithms, such as TextBoxes [1] based on the one-stage target detector SSD [2] algorithm that adapts the target box to fit text lines with extreme aspect ratios, and CTPN [3] based on the Faster RCNN [4] architecture is improved. However, there are still some differences between text detection and target detection in terms of target information and the task itself, such as text is generally larger in length and width, often in the form of \"bars\", text lines may be dense, curved text, etc. Therefore, many algorithms dedicated to text detection have been derived, such as EAST [5], PSENet [6], DBNet [7], etc. DBNet [7], etc.\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/548b50212935402abb2e671c158c204737c2c64b9464442a8f65192c8a31b44d\" width=\"500\"></center>\n",
    "<center>Figure6 Text detection task example</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "The more popular text detection algorithms can be roughly divided into two categories of text detection algorithms **regression based** and **segmentation based**, there are also some algorithms that combine the two. Regression-based algorithms borrow from the general object detection algorithm, by setting the anchor regression detection box, or directly do pixel regression, such methods are better for regular shape text detection, but the detection of irregularly shaped text will be relatively poor, for example, CTPN [3] is better for horizontal text detection, but worse for tilted and curved text detection, SegLink [8] is better for long text, but worse for sparsely distributed text; segmentation-based algorithms introduced Mask-RCNN [9], which can reach a higher level of detection in various scenes and for various shapes of text, but the disadvantage is that post-processing is generally more complicated, so there is often a speed problem and the detection of overlapping text cannot be solved.\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/4f4ea65578384900909efff93d0b7386e86ece144d8c4677b7bc94b4f0337cfb\" width=\"800\"></center>\n",
    "<center>Figure7 Overview of text detection algorithms</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/473ba28cd0274d568f90eb8ca9e78864d994f3ebffe6419cb638e193c607b7b3)|![](https://ai-studio-static-online.cdn.bcebos.com/e968807b3ed9493cab20f3be0d8dc07b0baf8b8cecb24ee99ccda9d3a241832a)|![](https://ai-studio-static-online.cdn.bcebos.com/53b9e85ce46645c08481d7d7377720f5eea5ac30e37e4e9c9930e1f26b02e278)\n",
    "|---|---|---|\n",
    "<center>Figure8 (Left) Regression-based CTPN [3] algorithm to optimize anchor (Middle) Segmentation-based DB [7] algorithm to optimize post-processing (Right) Regression+segmentation SAST [10] algorithm</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "Text detection related technologies will be explained in detail and practical in Chapter 2„ÄÇ\n",
    "\n",
    "## 2.2 Text Recognition\n",
    "\n",
    "The task of text recognition is to recognize the text content in an image, and the general input comes from the text area of the image text truncated from the text box obtained by text detection. Text recognition can generally be divided into two categories according to the shape of the text to be recognized, **regular text recognition** and **irregular text recognition**. Regular text mainly refers to printed fonts, scanned text, etc., and the text is roughly in the horizontal line position; irregular text is often not in the horizontal position, and there are problems such as bending, obscuring and blurring. Irregular text scenario is very challenging and is also the main research direction in the field of text recognition at present.\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/b292f21e50c94debab7496d4ced96a93774a8525c12346f49cb151bde2a58fe8)\n",
    "<center>Figure9 (Left) Regular text vs. (Right) Irregular text</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "Algorithms for regular text recognition can be broadly classified into CTC-based and Sequence2Sequence-based depending on the decoding method, with different processing methods for transforming the sequence features learned by the network into the final recognition results. The CTC-based algorithm is represented by the classical CRNN [11].\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/403ca85c59d344f88d3b1229ca14b1e90c5c73c9f1d248b7aa94103f9d0af597)\n",
    "<center>Figure10 CTC-based recognition algorithm vs. Attention-based recognition algorithm</center>\n",
    "\n",
    "Irregular text recognition algorithms are more abundant compared to the methods such as STAR-Net [12], which corrects irregular text into regular rectangles before recognition by adding correction modules such as TPS; Attention-based methods such as RARE [13] enhance the focus on the correlation between the parts of the sequence; segmentation-based methods treat each character of a text line as an independent individual. Compared with recognizing the entire text line after doing correction, it is easier to recognize the segmented individual characters; in addition, with the rapid development of Transformer [14] and validation of its effectiveness in various tasks in recent years, a number of Transformer-based text recognition algorithms have also emerged, and such methods use the transformer structure to solve the CNN's long dependency modeling limitations of CNNs and have also achieved good results.\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/0fa30c3789424473ad9be1c87a4f742c1db69e3defb64651906e5334ed9571a8)\n",
    "<center>Figure11 Character segmentation based recognition algorithm [15]</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "Text recognition related technologies will be explained and practiced in detail in Chapter 3.\n",
    "\n",
    "## 2.3 Document Structured Recognition\n",
    "\n",
    "OCR technology in the traditional sense can solve the detection and recognition needs of text, but in practical application scenarios, what is ultimately needed to obtain is often structured information, such as information formatting extraction of ID cards and invoices, structured identification of forms, etc., mostly applied in scenarios such as express document extraction, contract content comparison, financial factoring sheet information comparison, logistics industry document identification, etc. OCR results + post-processing is A common structured solution, but the process is often complex, and the post-processing requires fine design and poor generalization. In the context of the gradual maturity of OCR technology and the growing demand for structured information extraction, various technologies on intelligent document analysis such as layout analysis, form recognition, and key information extraction have received more and more attention and research.\n",
    "\n",
    "* **Layout Analysis**\n",
    "\n",
    "Layout Analysis focuses on content classification of document images, and the categories can generally be classified as plain text, headings, tables, images, etc. Existing methods generally treat different plates in a document as different targets for detection or segmentation, such as Soto Carlos [16] combined contextual information and used the inherent location information of the document content to improve the region detection performance based on the target detection algorithm Faster R-CNN; Sarkar Mausoom [17] et al. proposed a priori-based segmentation mechanism to train document segmentation models on very high-resolution images, which solves the problem of indistinguishable and thus merged dense regions with different structures due to excessive reduction of the original image.\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/dedb212e8972497998685ff51af7bfe03fdea57f6acd450281ad100807086e1a)\n",
    "<center>Figure12 Layout analysis task diagram</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "* **Table Recognition**\n",
    "\n",
    "The task of Table Recognition is to recognize and convert table information in a document to an excel file. In addition to the complexity of table types and styles in text images, such as different row merges, different content text types, etc., the style of the document and the lighting environment in which it was taken pose great challenges for table recognition. These challenges make table recognition a difficult area of research in document understanding.\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/47119a2a2f9a45788390d6506f90d5de7449738008aa4c0ab619b18f37bd8d57)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/22ca5749441441e69dc0eaeb670832a5d0ae0ce522f34731be7d609a2d36e8c1)\n",
    "<center>Figure13 Schematic diagram of the form recognition task</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "There is a richer variety of methods for table recognition, early traditional algorithms based on heuristic rules, such as T-Rect and other algorithms proposed by Kieninger [18] and others, generally through manually designed rules, connected domain detection and analysis processing; in recent years, with the development of deep learning, some CNN-based table structure recognition algorithms began to emerge, such as Siddiqui Shoaib Ahmed [19] et al. proposed DeepTabStR, Raja Sachin [20] et al. proposed TabStruct-Net, etc.; in addition, with the rise of Graph Neural Network (GN), some researchers also try to apply GN to the table structure recognition problem, based on the graph neural network, to table recognition as a graph reconstruction problem, such as TGRNet proposed by Xue Wenyuan [21] and others; end-to-end based methods directly use the network to complete the HTML representation output of table structures, and end-to-end methods mostly use Seq2Seq methods to complete the prediction of table structures, such as some Attention or Transformer based methods, such as TableMaster [22].\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/a9a3c91898c84f03b382583859526c4b451ace862dbc4a15838f5dde4d0ea657)\n",
    "<center>Figure14 Schematic diagram of the form identification method</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "* **Key Information Extraction(KIE)**\n",
    "\n",
    "Key Information Extraction (KIE) is an important task in Document VQA, which mainly extracts the required key information from images, such as name and citizenship number information from ID cards, and the type of such information is often fixed under a specific task, but varies between tasks.\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/8af011647bb4464f80d07f3efeac469baed27c8185ef4c4883a19f40e8ba91f5)\n",
    "<center>Figure15 DocVQA Task Schematic</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "KIE is usually divided in two subtasks.\n",
    "\n",
    "- SER: Semantic Entity Recognition classifies each detected text, e.g., into name, ID. The black and red boxes are shown in the figure below.\n",
    "- RE: Relation Extraction, classifies each detected text into questions and answers, for example. Then the corresponding answer is found for each question. In the figure below, the red and black boxes represent the questions and answers respectively, and the yellow lines represent the correspondence between the questions and answers.\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/2f1bc1a3e4a341ab9552bbf5f6c2be71ba78d7d65da64818b776efe0691e310b)\n",
    "<center>Figure16 ser with re tasks</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "The general KIE methods are based on Named Entity Recognition (NER) [4], but these methods only use textual information in images, lacking the use of visual and structural information, and therefore are not very accurate. Based on this, methods in recent years have started to fuse visual and structural information with textual information, and these methods can be classified into four types according to the principles used in fusing multimodal information as follows.\n",
    "\n",
    "- Grid-based methods\n",
    "- Token-Based Methods\n",
    "- GCN-based methods\n",
    "- End to End based methods\n",
    "\n",
    "<br>\n",
    "\n",
    "The techniques related to document analysis will be explained in detail and practiced in Chapter 6.\n",
    "\n",
    "## 2.4 Other related technologies\n",
    "\n",
    "The previous section introduces three key technologies in the field of OCR: text detection, text recognition, and document structured recognition. More introductions to other OCR-related cutting-edge technologies, including end-to-end text recognition, image pre-processing techniques in OCR, and OCR data synthesis, can be found in Chapters 7 and 8 of the tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Industrial practice of OCR technology\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/3d5f18f7598f405884fa2fab041c95ce415af40712e9489996747f9d122c3d90)\n",
    "\n",
    "> If you were the Wang, how to deal with?  \n",
    "> 1. I can't, I can't, I quit üò≠\n",
    "> 2. suggest the boss to find an outsourcing company or a commercial solution, spend the boss's money anyway üòä\n",
    "> 3. look for similar projects online, oriented to Github programming üòè\n",
    "\n",
    "<br>\n",
    "\n",
    "OCR technology eventually has to be put into industrial practice. Although there are many academic studies on OCR technology and the commercial application of OCR technology has been relatively mature compared with other AI technologies, there are still some difficulties and challenges in the actual industrial application. The following article will analyze from two perspectives: technology and industrial practice.\n",
    "\n",
    "\n",
    "## 3.1 Industry Practice Difficulties\n",
    "\n",
    "\n",
    "In actual industry practice, developers often need to rely on open source community resources to start or advance their projects, and developers using open source models often face three major challenges.\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/7e5e79240b9c4f13b675b56bc12edf540f159c922bf24e3cbc4a0635a356c7f9)\n",
    "<center>Figure17 OCR technology industry practice three major challenges</center>\n",
    "\n",
    "**1. Can't find, can't choose**\n",
    "\n",
    "The open source community is rich in resources, but information asymmetry leads to developers not being able to efficiently solve the pain point problem. On the one hand, the open source community is too rich in resources, so developers cannot quickly find a project matching the business needs from the massive code warehouse, i.e., there is the problem of \"not being able to find\"; on the other hand, in algorithm selection, the metrics on the English public data set cannot provide direct reference to the Chinese scenarios that developers often face. On the other hand, when it comes to algorithm selection, the metrics on the English public dataset cannot provide direct reference for the Chinese scenarios that developers often face.\n",
    "\n",
    "**2. Not applicable to industrial scenarios**\n",
    "\n",
    "The work in the open source community tends to be more effect-optimized, such as open source or replication of academic paper code, and generally focuses more on algorithm effects, with much less work to balance consideration of model size and speed, while model size and prediction time consumption are two indicators that cannot be ignored in industrial practice, and are as important as model effects. Both mobile and server side, the number of images to be recognized is often very large, and they all want smaller models, higher accuracy and faster prediction speed; GPU is too expensive, and it is better to use CPU to run more economically. The lighter the model is, the less resources it takes up under the premise of meeting business requirements.\n",
    "\n",
    "**3. Optimization is difficult and training deployment is problematic**\n",
    "\n",
    "Direct use of open source algorithms or models generally can not directly meet business needs, the actual business scenarios, OCR faces a variety of problems, business scenario personalization often requires custom data sets to retrain, the existing open source projects, the cost of experimenting with various optimization methods is high. In addition, OCR application scenarios are very rich, with a wide range of application needs on the server side and various mobile devices, and the diversification of hardware environments requires support for rich deployment methods, while the open source community projects focus more on algorithms and models, which are clearly undersupported in this part of predictive deployment. To make OCR technology from the algorithm on the paper to the technology on the ground application, there are high requirements for developers' algorithm and engineering ability.\n",
    "\n",
    "## 3.2 Industrial-grade OCR development kit PaddleOCR\n",
    "\n",
    "OCR industry practice needs a complete full-flow solution to speed up the R&D progress and save precious R&D time. In other words, the ultra-lightweight model and its full-flow solution can be said to be in immediate need especially for mobile and embedded devices with limited computing power and storage space.\n",
    "\n",
    "In this context, the industrial-grade OCR development kit [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR) was born.\n",
    "\n",
    "The construction idea of PaddleOCR starts from user portrait and demand, relies on the core framework of flying paddle, selects and reproduces rich cutting-edge algorithms, develops PP characteristic models more suitable for industrial implementation based on the reproduced algorithms, and opens up the training and pushing integration to provide a variety of prediction deployment methods to meet different demand scenarios of practical applications.\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/e09929b4a31e44f9b5e3d542d12411332669d2e1a21d45ad88b1dd91142ec86c)\n",
    "<center>Figure18 Panoramic view of PaddleOCR development kit</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "As you can see from the panorama, PaddleOCR relies on the Flying Paddle core framework, which provides rich solutions at the level of model algorithms, pre-trained model libraries, industrial-grade deployment, and provides data synthesis and semi-automatic data annotation tools to meet the data production needs of developers.\n",
    "\n",
    "**On the model algorithm level**, PaddleOCR provides solutions for **text detection recognition** and **document structured analysis** for two types of tasks respectively. In text detection and recognition, PaddleOCR has replicated or open-sourced four text detection algorithms, eight text recognition algorithms, and one end-to-end text recognition algorithm, and has developed the PP-OCR series of general text detection and recognition solutions on this basis; in document structured analysis, PaddleOCR provides algorithms for layout analysis, table recognition, key information extraction, named entity recognition and other algorithms, and based on this, PP-Structure document analysis solution is proposed. The rich selection of algorithms can meet the needs of developers in different business scenarios, and the unified code framework is also convenient for developers to optimize and compare the performance of different algorithms.\n",
    "\n",
    "**On the Pre-trained model library level**,Based on the PP-OCR and PP-Structure solutions, PaddleOCR has developed and open-sourced a series of special models for industry practice, including general-purpose, ultra-lightweight and multilingual text detection and recognition models, and complex document analysis models. Developers can either apply them directly to business scenarios or use business data for simple finetune to easily develop \"practical models\" for their business needs.\n",
    "\n",
    "**On the industrial deployment level**, PaddleOCR provides a server-side prediction scheme based on Paddle Inference, a service-based deployment scheme based on Paddle Serving, and an end-side deployment scheme based on Paddle-Lite to meet the deployment requirements in different hardware environments, as well as a PaddleSlim-based model compression scheme can further compress the model size. All of the above deployment methods have completed the whole process of training and pushing to ensure that developers can deploy efficiently and reliably.\n",
    "\n",
    "**On the utill tools level**, PaddleOCR provides PPOCRLabel, a semi-automatic data labeling tool, and Style-Text, a data synthesis tool, to help developers more easily produce the data sets and labeling information needed for model training. As the industry's first open source semi-automatic OCR data labeling tool, PPOCRLabel addresses the problem of boring and tedious labeling process, high mechanical nature, and expensive time and money costs for manual labeling of large amount of training data, with built-in PP-OCR model to achieve pre-labeling and manual verification of labeling mode, which can greatly improve labeling efficiency and save labor costs. The data synthesis tool Style-Text mainly solves the problem that the real data of the actual scene is seriously insufficient and the traditional synthesis algorithm cannot synthesize the text style (font, color, spacing, background), only a small number of target scene images, you can synthesize a large number of text images similar to the style of the target scene.\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/90a358d6a62c49b7b8db47e18c77878c60f80cf9c81541bfa3befea68d9dbc0f)\n",
    "<center>Figure19 Diagram of PPOCRLabel</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/b63b10bc530c42bea3d3b923da6000f1cfef006d7eec4ff3bdc0439bd9c333c9)\n",
    "<center>Figure20 Style-Text synthesis effect example</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "### 3.2.1 PP-OCR and PP-Structrue\n",
    "\n",
    "The PP series of featured models are models that are deeply optimized by each vision development kit of Flying Paddle for industrial practice needs, striving for a balance of speed and accuracy.PaddleOCR's PP series of featured models include the PP-OCR series of models for text detection and recognition tasks and the PP-Structure series of models for document analysis.\n",
    "\n",
    "**(1) PP-OCR Chinese and English models**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/3372558042044d43983b815069e1e43cb84432b993ed400f946976e75bd51f38)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/f0a0b936382c42dd8809e98759b4c84434d79386606b4d5b8a86416db6dbaeee)\n",
    "<center>Figure21 PP-OCR Chinese and English model recognition results example</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "The typical two-stage OCR algorithm used in PP-OCR Chinese and English models, i.e. the composition of detection model + recognition model, has the following specific algorithmic framework.\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/8af1371b5e3c486bb90a041903200c7c666c8bbc98c245dc802ff8c4da98617e)\n",
    "<center>Figure22 PP-OCR system pipeline diagram</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "As you can see, in addition to the input and output, the PP-OCR core framework contains 3 modules, which are: text detection module, detection box correction module, and text recognition module.\n",
    "- Text detection module: the core is a text detection model trained based on the [DB](https://arxiv.org/abs/1911.08947) detection algorithm, which detects text areas in images.\n",
    "- detection box correction module: the detected text box is input into the detection frame correction module, at this stage, the four-point representation of the text box is corrected to a rectangular box to facilitate subsequent text recognition, on the other hand, text direction judgment and correction will be performed, for example, if the text line is judged to be upside down, it will be turned, this function is achieved by training a text direction classifier.\n",
    "- Text recognition module: finally the text recognition module performs text recognition on the corrected detection box and gets the text content inside each text box, the classical text recognition algorithm [CRNN] used in PP-OCR(https://arxiv.org/abs/1507.05717)„ÄÇ\n",
    "\n",
    "PaddleOCR has introduced the PP-OCR [23] and PP-OCRv2 [24] models.\n",
    "\n",
    "PP-OCR model is divided into mobile version (lightweight version) and server version (general-purpose version), where the mobile version model is mainly optimized based on the lightweight backbone network MobileNetV3, and the optimized model (detection model + text direction classification model + recognition model) is only 8.1M in size, with an average single image prediction time of 350ms on CPU and about 110ms on T4 and GPU. More PP-OCR evaluation data can be found in [benchmark].(https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.2/doc/doc_ch/benchmark.md)„ÄÇ\n",
    "\n",
    "PP-OCRv2 maintains the overall framework of PP-OCR, and mainly makes further strategic optimization on the effect. The improvement includes 3 aspects.\n",
    "- In model effect, over 7% improvement compared to PP-OCR mobile version.\n",
    "- In terms of speed, over 220% improvement relative to the PP-OCR server version.\n",
    "- In terms of model size, with a total size of 11.6M, both the server side and mobile side can be easily deployed.\n",
    "\n",
    "The specific optimization strategies of PP-OCR and PP-OCRv2 will be explained in detail in Chapter 4.\n",
    "\n",
    "In addition to the Chinese and English models, PaddleOCR has also trained and open-sourced English numeric models and multilingual recognition models based on different datasets, all of which are ultra-lightweight models and suitable for different language scenarios.\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/5978652a826647b98344cf61aa1c2027662af989b73e4a0e917d83718422eeb0)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/1a8a8e24b5a440d388dae767adf0ea9c049335b04e964abbb176f58c5b028d7e)\n",
    "<center>Figure23 Schematic diagram of the recognition effect of English digital model and multilingual model of PP-OCR</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "**Ôºà2ÔºâPP-Structure Document Analysis Model**\n",
    "\n",
    "PP-Structure support layout analysis, table recognition and DocVQA in total three tasks.\n",
    "\n",
    "The core function points of PP-Structure are as follows.\n",
    "- Support layout analysis of documents in the form of images, which can be divided into 5 types of areas: text, headings, tables, images and lists (used in conjunction with Layout-Parser)\n",
    "- Support for extracting text, title, image and list areas into text fields (used in conjunction with PP-OCR)\n",
    "- Support structured analysis of table areas and output Excel files for final results\n",
    "- Support both Python whl package and command line, easy to use\n",
    "- Support two types of tasks custom training for layout analysis and table structuring\n",
    "- Support VQA task-SER and RE\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/129708c265644dbc90d6c8f7db224b3a6f11f37bb586463a82e7ccb50bcc2e76)\n",
    "<center>Figure24 Schematic diagram of PP-Structure system (this diagram contains only layout analysis + table identification)</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "The specific scheme of PP-Structure will be explained in detail in Chapter 6.\n",
    "\n",
    "### 3.2.2 Â∑•‰∏öÁ∫ßÈÉ®ÁΩ≤ÊñπÊ°à\n",
    "\n",
    "The first one uses PaddlePaddle API to build network structures for training, the second one is based on the PaddlePaddle Suite series, which provides a rich library of models, simple and easy-to-use APIs, with out-of-the-box use, including visual model library PaddleCV, intelligent speech library PaddleSpeech and PaddleNLP, a natural language processing library, etc. The third uses models output from third-party frameworks (PyTorh, ONNX, TensorFlow, etc.) using X2Paddle tools.\n",
    "\n",
    "The flying paddle model can be compressed, quantized, and distilled with the PaddleSlim tool, which supports five deployment options, namely serviced Paddle Serving, server-side/cloud-side Paddle Inference, mobile-side/edge-side Paddle Lite, and web front-end Paddle.js. For hardware not supported by Paddle such as MCU, Horizon, Kunyun and other domestic chips, they can be transformed into third-party frameworks supporting ONNX with the help of Paddle2ONNX.\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/c9ffe78e7db14e4eb103e7f393a16fbf2ab438540250474a8e0e7adc4aeb7ee0)\n",
    "<center>Figure25 Flying Paddle Support Deployment Method</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "Paddle Inference supports server-side and cloud deployment with high performance and versatility, with deep adaptations and optimizations for different platforms and different application scenarios. Paddle Inference is a native inference library for flying paddles, ensuring that models are ready for training and fast deployment on the server side, suitable for deploying algorithmically complex models on high-performance hardware using multiple application language environments The hardware covers x86 CPU, Nvidia GPU, and AI accelerator pedals such as Baidu Kunlun XPU and Huawei Rising.\n",
    "\n",
    "Paddle Lite is an end-side inference engine with light weight and high performance features, which is deeply configured and optimized for end-side devices and various application scenarios. It currently supports multiple platforms such as Android, IOS, embedded Linux devices, macOS, etc. The hardware covers ARM CPUs and GPUs, X86 CPUs and new hardware such as Baidu Kunlun, Huawei Sunrise and Kirin, and Rexchip Micro.\n",
    "\n",
    "Paddle Serving is a set of high-performance service framework designed to help users to quickly deploy models in the cloud as a service in a few steps. Currently Paddle Serving supports custom pre and post processing, model combination, model hot-loading update, multi-machine multi-card multi-model, distributed reasoning, K8S deployment, secure gateway and model encryption deployment, support for multi-language multi-client access, etc. Paddle Serving also officially provides deployment examples for more than 40 models including PaddleOCR. to help users get started faster.\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/4d8063d74194434ea9b7c9f81c7fbdfd2131e13770124d2e99c1b9670f12e019)\n",
    "<center>Figure26 Flying Paddle Support Deployment Method</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "The above deployment scheme will be explained and practiced in detail in Chapter 5 based on the PP-OCRv2 model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Summary\n",
    "\n",
    "This section first introduces the application scenarios and cutting-edge algorithms of OCR technology, and then analyzes the difficulties and three major challenges of OCR technology in industrial practice.\n",
    "\n",
    "The subsequent chapters of this tutorial are organized as follows.\n",
    "\n",
    "* Chapters 2 and 3 introduce the detection and recognition technologies and practice respectively.\n",
    "* Chapter 4 introduces PP-OCR optimization strategy.  \n",
    "* Chapter 5 conducts predictive deployment in practice.  \n",
    "* Chapter 6 introduces document structuring.  \n",
    "* Chapter 7 introduces other OCR-related algorithms such as end-to-end, data pre-processing, and data synthesis.  \n",
    "* Chapter 8 introduces OCR-related datasets and data synthesis tools.\n",
    "\n",
    "# Reference\n",
    "\n",
    "[1] Liao, Minghui, et al. \"Textboxes: A fast text detector with a single deep neural network.\" Thirty-first AAAI conference on artificial intelligence. 2017.\n",
    "\n",
    "[2] Liu W, Anguelov D, Erhan D, et al. Ssd: Single shot multibox detector[C]//European conference on computer vision. Springer, Cham, 2016: 21-37.\n",
    "\n",
    "[3] Tian, Zhi, et al. \"Detecting text in natural image with connectionist text proposal network.\" European conference on computer vision. Springer, Cham, 2016.\n",
    "\n",
    "[4] Ren S, He K, Girshick R, et al. Faster r-cnn: Towards real-time object detection with region proposal networks[J]. Advances in neural information processing systems, 2015, 28: 91-99.\n",
    "\n",
    "[5] Zhou, Xinyu, et al. \"East: an efficient and accurate scene text detector.\" Proceedings of the IEEE conference on Computer Vision and Pattern Recognition. 2017.\n",
    "\n",
    "[6] Wang, Wenhai, et al. \"Shape robust text detection with progressive scale expansion network.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.\n",
    "\n",
    "[7] Liao, Minghui, et al. \"Real-time scene text detection with differentiable binarization.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. No. 07. 2020.\n",
    "\n",
    "[8] Deng, Dan, et al. \"Pixellink: Detecting scene text via instance segmentation.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 32. No. 1. 2018.\n",
    "\n",
    "[9] He K, Gkioxari G, Doll√°r P, et al. Mask r-cnn[C]//Proceedings of the IEEE international conference on computer vision. 2017: 2961-2969.\n",
    "\n",
    "[10] Wang P, Zhang C, Qi F, et al. A single-shot arbitrarily-shaped text detector based on context attended multi-task \n",
    "learning[C]//Proceedings of the 27th ACM international conference on multimedia. 2019: 1277-1285.\n",
    "\n",
    "[11] Shi, B., Bai, X., & Yao, C. (2016). An end-to-end trainable neural network for image-based sequence recognition and its application to scene text recognition. IEEE transactions on pattern analysis and machine intelligence, 39(11), 2298-2304.\n",
    "\n",
    "[12] Star-Net Max Jaderberg, Karen Simonyan, Andrew Zisserman, et al. Spa- tial transformer networks. In Advances in neural information processing systems, pages 2017‚Äì2025, 2015.\n",
    "\n",
    "[13] Shi, B., Wang, X., Lyu, P., Yao, C., & Bai, X. (2016). Robust scene text recognition with automatic rectification. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 4168-4176).\n",
    "\n",
    "[14] Sheng, F., Chen, Z., & Xu, B. (2019, September). NRTR: A no-recurrence sequence-to-sequence model for scene text recognition. In 2019 International Conference on Document Analysis and Recognition (ICDAR) (pp. 781-786). IEEE.\n",
    "\n",
    "[15] Lyu P, Liao M, Yao C, et al. Mask textspotter: An end-to-end trainable neural network for spotting text with arbitrary shapes[C]//Proceedings of the European Conference on Computer Vision (ECCV). 2018: 67-83.\n",
    "\n",
    "[16] Soto C, Yoo S. Visual detection with context for document layout analysis[C]//Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019: 3464-3470.\n",
    "\n",
    "[17] Sarkar M, Aggarwal M, Jain A, et al. Document Structure Extraction using Prior based High Resolution Hierarchical Semantic Segmentation[C]//European Conference on Computer Vision. Springer, Cham, 2020: 649-666.\n",
    "\n",
    "[18] Kieninger T, Dengel A. A paper-to-HTML table converting system[C]//Proceedings of document analysis systems (DAS). 1998, 98: 356-365.\n",
    "\n",
    "[19] Siddiqui S A, Fateh I A, Rizvi S T R, et al. Deeptabstr: Deep learning based table structure recognition[C]//2019 International Conference on Document Analysis and Recognition (ICDAR). IEEE, 2019: 1403-1409.\n",
    "\n",
    "[20] Raja S, Mondal A, Jawahar C V. Table structure recognition using top-down and bottom-up cues[C]//European Conference on Computer Vision. Springer, Cham, 2020: 70-86.\n",
    "\n",
    "[21] Xue W, Yu B, Wang W, et al. TGRNet: A Table Graph Reconstruction Network for Table Structure Recognition[J]. arXiv preprint arXiv:2106.10598, 2021.\n",
    "\n",
    "[22] Ye J, Qi X, He Y, et al. PingAn-VCGroup's Solution for ICDAR 2021 Competition on Scientific Literature Parsing Task B: Table Recognition to HTML[J]. arXiv preprint arXiv:2105.01848, 2021.\n",
    "\n",
    "[23] Du Y, Li C, Guo R, et al. PP-OCR: A practical ultra lightweight OCR system[J]. arXiv preprint arXiv:2009.09941, 2020.\n",
    "\n",
    "[24] Du Y, Li C, Guo R, et al. PP-OCRv2: Bag of Tricks for Ultra Lightweight OCR System[J]. arXiv preprint arXiv:2109.03144, 2021.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
